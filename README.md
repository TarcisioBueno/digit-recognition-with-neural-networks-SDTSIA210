# MNIST Neural Network from Scratch and Autoencoders

This repository contains a Jupyter Notebook that explores two main topics:

1. **Building a Simple Neural Network (Linear Classifier) from Scratch with NumPy:**
   - Implements a basic linear classifier for the MNIST dataset using only NumPy.
   - Covers forward propagation, softmax activation, gradient calculation, and parameter updates.
   - Demonstrates the training process and evaluates the classifier's performance on the MNIST dataset.
   - Analyzes the classification results and discusses potential improvements.

2. **Implementing Autoencoders with Keras:**
   - Introduces autoencoders and their relationship to Principal Component Analysis (PCA).
   - Implements a simple linear autoencoder with Keras and compares its learned representations to PCA components.
   - Builds a more complex autoencoder with multiple layers and non-linear activations (ReLU).
   - Explores the concept of denoising autoencoders and trains a model to reconstruct noisy images.
   - Visualizes the reconstructed images and discusses the effectiveness of the denoising autoencoder.


## Getting Started

To run the notebook:

1. Make sure you have Jupyter Notebook or Google Colab installed.
2. Clone this repository to your local machine.
3. Open the notebook (`TP_MNIST_with_NN.ipynb`) in Jupyter Notebook or Google Colab.
4. Execute the cells in the notebook to see the results.

## Requirements

- Python 3.x
- NumPy
- TensorFlow
- Keras
- Matplotlib
- scikit-learn
- Pandas

You can install the required libraries using `pip`:
